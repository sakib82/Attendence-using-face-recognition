{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "fo = open(\"input.txt\",\"r\")\n",
    "# print(\"Opening input file.......\",fo.name)\n",
    "\n",
    "# from PyQt5.Qt import PYQT_VERSION_STR\n",
    "# print(\"PyQt version:\", PYQT_VERSION_STR)\n",
    "\n",
    "print(\"File name : \",fo.name)\n",
    "print(\"Open or closed : \",fo.closed)\n",
    "print(\"Opening mode : \",fo.mode)\n",
    "# print(\"Softspace flag : \", fo.softspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os\n",
    "dir_path = os.getcwd() # current directory\n",
    "print(dir_path)\n",
    "camera = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Camera test\")\n",
    "\n",
    "i = 0\n",
    "imgpath = \"C:/Users/Sakib/Desktop/New/\"\n",
    "name = 'image' + str(i) + '.png'\n",
    "\n",
    "for i in range(4):\n",
    "\treturn_value, image = camera.read()\n",
    "\tcv2.imwrite(os.path.join(imgpath,name),image)\n",
    "#   cv2.imwrite(os.path.join(path,imgpath+'opencv' + str(i) + '.png'),image)\n",
    "# \tcv2.imshow(os.path.join(path,\"Capturing image  : \",image)\n",
    "\ti = i+1\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Camera test\")\n",
    "del(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run webcam, take photo and store in a pre-specified directory (Successful)\n",
    "Name : Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "dir_path = os.getcwd() # current directory\n",
    "print(\"Current directory : \" , dir_path)\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Camera test\")\n",
    "\n",
    "i = 0\n",
    "img_num = 15\n",
    "imgpath = \"C:/Users/Sakib/Desktop/New/\"\n",
    "\n",
    "print(\" Images are being taken .............\" )\n",
    "for i in range(img_num+1):\n",
    "\tname = 'train' + str(i) + '.png'\n",
    "\treturn_value, image = camera.read()\n",
    "\tcv2.imwrite(os.path.join(imgpath,name),image)\n",
    "\tcv2.imshow(\"Camera test\",image)\n",
    "#   cv2.imwrite(os.path.join(path,imgpath+'opencv' + str(i) + '.png'),image)\n",
    "# \tcv2.imshow(os.path.join(path,\"Capturing image  : \",image)\n",
    "\ti = i+1\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Camera test\")\n",
    "del(camera)\n",
    "print(\"............ COMPLETE ................\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run face detection in those taken photoes(Successful)\n",
    "Name : Face Detect // ( next : face recognition) ( separate framed faces from the video )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "cascade_path = \"C:/Users/Sakib/Desktop/haarcascade_frontalface_default.xml\"\n",
    "facecascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "img_num = 5\n",
    "\n",
    "for i in range(1,img_num+1):\n",
    "\tname = 'train' + str(i) + '.png'\n",
    "\timage_path = \"C:/Users/Sakib/Desktop/New/\"\n",
    "\timage_name = image_path+name\n",
    "\tprint(image_path+name)\n",
    "    \n",
    "\timage = cv2.imread(image_name)\n",
    "\timage = cv2.resize(image,(800,600))\n",
    "\tgray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\tfaces = facecascade.detectMultiScale(gray,scaleFactor = 1.3,\n",
    "                                    minNeighbors=2,\n",
    "                                    minSize=(10,10),\n",
    "                                    flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "# cv2.CascadeClassifier.detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]])\n",
    "\n",
    "\tprint(\"Found {0} faces.\".format(len(faces)))\n",
    "\n",
    "\n",
    "\tfor(x,y,w,h) in faces:\n",
    "\t\tcv2.rectangle(image,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\tcv2.imshow(name,image)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyWindow(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select a image and detect faces in that image(Successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 faces.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "imagepath = \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/test2.jpg\"\n",
    "cascadpath =  \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\"\n",
    "facecascade = cv2.CascadeClassifier(cascadpath)\n",
    "\n",
    "image = cv2.imread(imagepath)\n",
    "image = cv2.resize(image,(800,600))\n",
    "# cv2.imshow(\"OK?\",image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyWindow(\"OK?\")\n",
    "# image = cv2.imread(imagepath)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = facecascade.detectMultiScale(gray,scaleFactor = 1.3,\n",
    "                                    minNeighbors=2,\n",
    "                                    minSize=(10,10),\n",
    "                                    flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "# cv2.CascadeClassifier.detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]])\n",
    "print(\"Found {0} faces.\".format(len(faces)))\n",
    "\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"Faces Found\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Faces Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect faces in Video (successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('C:/Users/Sakib/Desktop/vid4.mp4')\n",
    "\n",
    "cascadpath =  \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\"\n",
    "facecascade = cv2.CascadeClassifier(cascadpath)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    faces = facecascade.detectMultiScale(frame,scaleFactor = 1.3,\n",
    "                                    minNeighbors=2,\n",
    "                                    minSize=(10,10),\n",
    "                                    flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('frame',frame) #cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run webcam and save the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c79285573b2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamedWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hello\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hello\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, 20.0, (640, 480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "#         frame = (frame,0)\n",
    "        cv2.namedWindow(\"hello\")\n",
    "        cv2.imshow(\"hello\", frame)\n",
    "        output.write(frame)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(\"Cap is not opened\")\n",
    "        break\n",
    "        \n",
    "cv2.detroyWindow(\"hello\")\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "dir_path = os.getcwd() # current directory\n",
    "print(\"Current directory : \" , dir_path)\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Capturing Photoes\")\n",
    "\n",
    "i = 0\n",
    "img_num = 9\n",
    "imgpath = \"C:/Users/Sakib/Desktop/New/\"\n",
    "\n",
    "print(\" Images are being taken .............\" )\n",
    "for i in range(img_num+1):\n",
    "# \tname = 'train' + str(i)  + '.jpg'\n",
    "\tname = 'train.' + str(i)\n",
    "\treturn_value, image = camera.read()\n",
    "\tcv2.imwrite(os.path.join(imgpath,name+\".jpg\"),image)\n",
    "\tcv2.imshow(\"Capturing Photoes\",image)\n",
    "#   cv2.imwrite(os.path.join(path,imgpath+'opencv' + str(i) + '.png'),image)\n",
    "# \tcv2.imshow(os.path.join(path,\"Capturing image  : \",image)\n",
    "\ti = i+1\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Capturing Photoes\")\n",
    "del(camera)\n",
    "print(\"............ COMPLETE ................\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a recognizer (.... WORKING.....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "i = 0\n",
    "\n",
    "name = 'train.' + str(i) \n",
    "image_path = \"C:/Users/Sakib/Desktop/New/\"\n",
    "image_name = image_path+name + '.jpg'\n",
    "print(\"image_path : \", image_path)  \n",
    "\n",
    "\n",
    "def getimageid(image_path):\n",
    "    \n",
    "    image_paths = [os.path.join(image_path, f) for f in os.listdir(image_path)]   \n",
    "#     print(image_paths) \n",
    "    \n",
    "    faces = []\n",
    "    IDs = []\n",
    "#     print(\"clear upto line 21\")\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        faceimg = cv2.imread(image_path)\n",
    "        print(\"clear upto read\", image_path)\n",
    "        faceimg = cv2.cvtColor(faceimg,cv2.COLOR_BGR2GRAY)\n",
    "        facenp = np.array(faceimg,'uint8')\n",
    "        \n",
    "        id = int(os.path.split(image_path)[-1].split(\".\")[1])\n",
    "        print(id)\n",
    "\n",
    "        faces.append(facenp)\n",
    "        IDs.append(id)\n",
    "\n",
    "#         cv2.imshow(\"Adding faces for traning\",facenp)\n",
    "#         cv2.waitKey(1)\n",
    "    return np.array(IDs), faces\n",
    "\n",
    "print(\"image_path in line 37 : \", image_path)\n",
    "Ids,faces  = getimageid(image_path)\n",
    "\n",
    "recognizer.train(faces,Ids)\n",
    "print(\"clear upto line 41\")\n",
    "recognizer.save(\"C:/Users/Sakib/Desktop/New/trainingdata.yml\")\n",
    "print(\"clear upto saving recognizer\")\n",
    "cv2.destroyAllWindows()\n",
    "print(\"clear upto last line\")\n",
    "print(\"...........DELETE THE YML FILE EVERY TIME........\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the recognizer and recognise the faces in live videos (....ALHAMDULILLAH.....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(\"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "rec = cv2.face.LBPHFaceRecognizer_create();\n",
    "rec.read(\"C:/Users/Sakib/Desktop/New/trainingdata.yml\")\n",
    "id=0\n",
    "font=(cv2.FONT_HERSHEY_COMPLEX_SMALL,5,1,0,4)\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        id,conf=rec.predict(gray[y:y+h,x:x+w])\n",
    "        if(id==2):\n",
    "            id=\"Sakib\"\n",
    "        if id==1:\n",
    "            id=\"showad\"\n",
    "        \n",
    "            \n",
    "        cv2.putText(img,str(id),(x,y+h),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,0,255),3)\n",
    "    cv2.imshow('img',img)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking how efficiently it detects the faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking how efficiently it detects the faces\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "image_path = \"C:/Users/Sakib/Desktop/lfw/\"\n",
    "cascadepath = \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\"\n",
    "facecascade = cv2.CascadeClassifier(cascadepath)\n",
    "\n",
    "for f in os.listdir(image_path):\n",
    "    image_way = image_path+f\n",
    "    print(image_way)\n",
    "    image = cv2.imread(image_way)\n",
    "    \n",
    "    image = cv2.resize(image,(800,600))\n",
    "#     cv2.imshow('image',image)\n",
    "# changing from (1.3, 2, (10,10) to (1.5, 2, (10,10) detects less faces.)\n",
    "#\n",
    "\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = facecascade.detectMultiScale(gray,scaleFactor = 1.3,\n",
    "                                    minNeighbors=2,\n",
    "                                    minSize=(10,10),\n",
    "                                    flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "# cv2.CascadeClassifier.detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]])\n",
    "    print(\"Found {0} faces.\".format(len(faces)))\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(image,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Faces Found\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(\"Faces Found\")\n",
    "    f = ''\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writing an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/Sakib/Desktop/Attendence-using-face-recognition/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-69781c71b010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mworkbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         xlsx_file = ZipFile(self.filename, \"w\", compression=ZIP_DEFLATED,\n\u001b[1;32m--> 655\u001b[1;33m                             allowZip64=self.allow_zip64)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Add XML sub-files to the Zip file with their Excel filename.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1202\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/Sakib/Desktop/Attendence-using-face-recognition/'"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "path = \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/\"\n",
    "workbook = xlsxwriter.Workbook( path )\n",
    "\n",
    "worksheet_data = workbook.add_worksheet('data')\n",
    "\n",
    "workbook.sheetnames['data'] == worksheet_data\n",
    "\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Workbook is created\n",
    "wb = Workbook() \n",
    "# add_sheet is used to create sheet.\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "sheet1.write(1, 0, 'Sakib')\n",
    "sheet1.write(2, 1, 'Showad')\n",
    "sheet1.write(3, 2, 'Shafkat')\n",
    "sheet1.write(4, 0, 'Nijhum')\n",
    "sheet1.write(5, 0, 'Ira')\n",
    "sheet1.write(6, 0, 'PITAMPURA')\n",
    "sheet1.write(7, 0, 'YAMUNA BANK')\n",
    "sheet1.write(8, 0, datetime.now())\n",
    "# ws.write(2, 2, xlwt.Formula(\"A3+B3\"))\n",
    "wb.save('CSE 801 Attendent.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from PyQt5.Qt import PYQT_VERSION_STR\n",
    "    print(\"PyQt version:\", PYQT_VERSION_STR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
