{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run webcam, take photo and store in a pre-specified directory (Successful)\n",
    "Name : Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory :  C:\\Users\\Sakib\\Desktop\\Attendence-using-face-recognition\n",
      " Images are being taken .............\n",
      "............ COMPLETE ................\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "dir_path = os.getcwd() # current directory\n",
    "print(\"Current directory : \" , dir_path)\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Capturing Photoes\")\n",
    "\n",
    "i = 0\n",
    "img_num = 2\n",
    "\n",
    "imgpath = \"C:/Users/Sakib/Desktop/New/\"\n",
    "\n",
    "print(\" Images are being taken .............\" )\n",
    "for i in range(img_num+1):\n",
    "\tname = 'train.' + str(i)  + '.jpg'\n",
    "\treturn_value, image = camera.read()\n",
    "\tcv2.imwrite(os.path.join(imgpath,name),image)\n",
    "\tcv2.imshow(\"Capturing Photoes\",image)\n",
    "#   cv2.imwrite(os.path.join(path,imgpath+'opencv' + str(i) + '.png'),image)\n",
    "# \tcv2.imshow(os.path.join(path,\"Capturing image  : \",image)\n",
    "\ti = i+1\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Capturing Photoes\")\n",
    "del(camera)\n",
    "print(\"............ COMPLETE ................\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run face detection in those taken photoes(Successful)\n",
    "Name : Face Detect // ( next : face recognition) ( separate framed faces from the video )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "cascade_path = \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\"\n",
    "facecascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "img_num = 10\n",
    "\n",
    "\n",
    "for i in range(1,img_num+1):\n",
    "\tname = 'train' + str(i) \n",
    "\timage_path = \"C:/Users/Sakib/Desktop/New/\"\n",
    "\timage_name = image_path+name + '.jpg'\n",
    "\tprint(image_path+name)\n",
    "    \n",
    "\timage = cv2.imread(image_name)\n",
    "\timage = cv2.resize(image,(800,600))\n",
    "\tgray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\tfaces = facecascade.detectMultiScale(gray,scaleFactor = 1.3,\n",
    "                                    minNeighbors=2,\n",
    "                                    minSize=(10,10),\n",
    "                                    flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "# cv2.CascadeClassifier.detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]])\n",
    "\n",
    "\tprint(\"Found {0} faces.\".format(len(faces)))\n",
    "\n",
    "\n",
    "\tfor(x,y,w,h) in faces:\n",
    "\t\tcv2.rectangle(image,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\tcv2.imshow(name,image)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyWindow(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select a image and detect faces in that image(Successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "imagepath = \"C:/Users/Sakib/Desktop/test1.jpg\"\n",
    "cascadpath = \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "facecascade = cv2.CascadeClassifier(cascadpath)\n",
    "\n",
    "image = cv2.imread(imagepath)\n",
    "image = cv2.resize(image,(800,600))\n",
    "# cv2.imshow(\"OK?\",image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyWindow(\"OK?\")\n",
    "# image = cv2.imread(imagepath)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = facecascade.detectMultiScale(gray,scaleFactor = 1.3,\n",
    "                                    minNeighbors=2,\n",
    "                                    minSize=(10,10),\n",
    "                                    flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "# cv2.CascadeClassifier.detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]])\n",
    "print(\"Found {0} faces.\".format(len(faces)))\n",
    "\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"Faces Found\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Faces Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect faces in Video (successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture('C:/Users/Sakib/Desktop/video2.mp4') # detect faces from video\n",
    "\n",
    "cascadpath = \"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\"\n",
    "facecascade = cv2.CascadeClassifier(cascadpath)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "#     print(success, frame)\n",
    "    if success:\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = facecascade.detectMultiScale(frame,scaleFactor = 1.3,\n",
    "                                        minNeighbors=2,\n",
    "                                        minSize=(10,10),\n",
    "                                        flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        #     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "        cv2.imshow(\"frame\",frame) #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... traindata.yml is successfully saved in C:/Users/Sakib/Desktop/New/ ......\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "name = 'train.' + str(i) \n",
    "image_path = \"C:/Users/Sakib/Desktop/New/\"\n",
    "image_name = image_path+name + '.jpg'  \n",
    "\n",
    "def getimageid(image_path):\n",
    "    \n",
    "    image_paths = [os.path.join(image_path, f) for f in os.listdir(image_path)]   \n",
    "#     print(image_paths) \n",
    "    \n",
    "    faces = []\n",
    "    IDs = []\n",
    "#     print(\"clear upto line 21\")\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        faceimg = cv2.imread(image_path)\n",
    "        faceimg = cv2.cvtColor(faceimg,cv2.COLOR_BGR2GRAY)\n",
    "        facenp = np.array(faceimg,'uint8')\n",
    "        \n",
    "        id = int(os.path.split(image_path)[-1].split(\".\")[1])\n",
    "\n",
    "        faces.append(facenp)\n",
    "        IDs.append(id)\n",
    "\n",
    "#         cv2.imshow(\"Adding faces for traning\",facenp)\n",
    "#         cv2.waitKey(1)\n",
    "    return np.array(IDs), faces\n",
    "\n",
    "Ids,faces  = getimageid(image_path)\n",
    "\n",
    "recognizer.train(faces,Ids)\n",
    "recognizer.save(\"C:/Users/Sakib/Desktop/New/trainingdata.yml\")\n",
    "print(\" ... traindata.yml is successfully saved in C:/Users/Sakib/Desktop/New/ ......\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "#print(\"...........DELETE THE YML FILE EVERY TIME........\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the recognizer and recognise the faces in live video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(\"C:/Users/Sakib/Desktop/Attendence-using-face-recognition/haarcascade_frontalface_default.xml\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "rec = cv2.face.LBPHFaceRecognizer_create();\n",
    "rec.read(\"C:/Users/Sakib/Desktop/New/trainingdata.yml\")\n",
    "id=0\n",
    "font=(cv2.FONT_HERSHEY_COMPLEX_SMALL,5,1,0,4)\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(100,110,110),1)\n",
    "        id,conf=rec.predict(gray[y:y+h,x:x+w])\n",
    "        if(id==1):\n",
    "            id=\"Sakib\"\n",
    "        if id==0:\n",
    "            id=\"showad\"\n",
    "        else:\n",
    "            id==\"Unknown Person\"\n",
    "        \n",
    "            \n",
    "        cv2.putText(img,str(id),(x,y+h),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(125,120,125),3)\n",
    "    cv2.imshow('img',img)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
